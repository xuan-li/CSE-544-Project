{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import threading\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "start_time = 1190146243\n",
    "end_time = 1192994591\n",
    "\n",
    "def load_data(input_name):\n",
    "    with open(input_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "def dump_data(data, output_name):\n",
    "    with open(output_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import mwclient\n",
    "from itertools import islice\n",
    "import calendar\n",
    "from urllib.parse import unquote\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "\n",
    "site = mwclient.Site('en.wikipedia.org')\n",
    "\n",
    "def get_page(title):\n",
    "    page = site.pages[unquote(unquote(title))]\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get revision records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revisions(title, prop='ids|timestamp|flags|comment|user|size'):\n",
    "    page = site.pages[unquote(unquote(title))]\n",
    "    revision = page.revisions(start=1192994591, end=1190146243, prop = prop)\n",
    "    return revision\n",
    "\n",
    "def revision_dataframe(title):\n",
    "    revisions = get_revisions(title, prop='ids|timestamp|user|size')\n",
    "    start = time.time()\n",
    "    series = []\n",
    "    for rev in revisions:\n",
    "        rev['timestamp'] = calendar.timegm(rev['timestamp'])\n",
    "        if 'user' not in rev:\n",
    "            rev['user'] = ''\n",
    "        if 'parentid' not in rev:\n",
    "            rev['parentid'] = ''\n",
    "        \n",
    "                \n",
    "        record = pd.Series(rev)\n",
    "        series.append(record)\n",
    "    if series:\n",
    "        return pd.DataFrame(series, index = range(len(series)))\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def collect_revisions(titles, nworkers = 4):\n",
    "    results = []\n",
    "    keys = []\n",
    "    i = 0\n",
    "    threads = [None] * nworkers\n",
    "    flags = [True] * nworkers\n",
    "    \n",
    "    def target(index, flags, results, keys,title):\n",
    "        try:\n",
    "            df = revision_dataframe(title)\n",
    "            f.write('word {} succeed\\n'.format(title))\n",
    "        except:\n",
    "            f.write('word {} fail\\n'.format(title))\n",
    "            df = None\n",
    "        if df is not None:\n",
    "            results.append(df)\n",
    "            keys.append(title)\n",
    "            assert(len(results) == len(keys))\n",
    "        flags[index] = True\n",
    "    f = open('log_spider.txt','w')\n",
    "    for title in titles:\n",
    "        index = 0\n",
    "        while True:\n",
    "            try:\n",
    "                index = flags.index(True)\n",
    "                flags[index] = False\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        t = threading.Thread(target = target, args = [index, flags, results, keys,title])\n",
    "        threads[index] = t\n",
    "        t.start()\n",
    "        i += 1\n",
    "        f.write('Processing word {}\\n'.format(i))\n",
    "        f.flush()\n",
    "    for thread in threads:\n",
    "        if thread:\n",
    "            thread.join()\n",
    "    return pd.concat(results, keys=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_series = load_data(\"data/dump/hot_words_100000.pkl\")\n",
    "#words_list = word_series.index\n",
    "#revision_df = collect_revisions(words_list)\n",
    "#dump_data(revision_df,\"data/dump/revision_records.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_df.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metadata\n",
    "\n",
    "language\n",
    "\n",
    "media_num\n",
    "\n",
    "categories\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "\n",
    "def get_metadata(title):\n",
    "    meta = {}\n",
    "    page = site.pages[unquote(unquote(title))]\n",
    "    categories = list(page.categories(generator=False))\n",
    "    langs = list(page.langlinks())\n",
    "    links = list(page.links(generator=False))\n",
    "    nimages = len(list(page.images(generator=False)))\n",
    "    meta['languages'] = langs\n",
    "    meta['links'] = links\n",
    "    meta['categories'] = categories\n",
    "    meta['image_num'] = nimages\n",
    "    return meta\n",
    "\n",
    "def collect_metas(titles, nworkers = 4):\n",
    "    metas = {}\n",
    "    i = 0\n",
    "    threads = [None] * nworkers\n",
    "    flags = [True] * nworkers\n",
    "    \n",
    "    def target(index, flags, title):\n",
    "        try:\n",
    "            meta = get_metadata(title)\n",
    "        except:\n",
    "            meta = None\n",
    "        if meta is not None:\n",
    "            metas[title] = meta\n",
    "        flags[index] = True\n",
    "    p =  IntProgress(max = 10000)  \n",
    "    p.discription = \"Running\"\n",
    "    display(p)\n",
    "    for title in titles:\n",
    "        index = 0\n",
    "        while True:\n",
    "            try:\n",
    "                index = flags.index(True)\n",
    "                flags[index] = False\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        t = threading.Thread(target = target, args = [index, flags, title])\n",
    "        threads[index] = t\n",
    "        t.start()\n",
    "        i += 1\n",
    "        p.value += 1\n",
    "        \n",
    "    for thread in threads:\n",
    "        if thread:\n",
    "            thread.join()\n",
    "    return metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dump/metadata_10000-20000.pkl exists\n",
      "data/dump/metadata_20000-30000.pkl exists\n",
      "data/dump/metadata_30000-40000.pkl exists\n",
      "data/dump/metadata_40000-50000.pkl exists\n",
      "data/dump/metadata_50000-60000.pkl exists\n",
      "data/dump/metadata_60000-70000.pkl exists\n",
      "data/dump/metadata_70000-80000.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299c10e693214e6389e54f40c99cb36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dump/metadata_80000-90000.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e770df5fde648bf911d229320ff496c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dump/metadata_90000-100000.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589a0e0165474bfbb1720a9ba21b992f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_series = load_data(\"data/dump/hot_words_100000.pkl\")\n",
    "words_list = word_series.index\n",
    "delta = 10000\n",
    "for j in range(1, 10):\n",
    "    if os.path.isfile(\"data/dump/metadata_{}-{}.pkl\".format(delta * j, delta * (j+1))):\n",
    "        print(\"data/dump/metadata_{}-{}.pkl exists\".format(delta * j, delta * (j+1)))\n",
    "        continue\n",
    "    print(\"data/dump/metadata_{}-{}.pkl\".format(delta * j, delta * (j+1)))\n",
    "    metas = collect_metas(words_list[delta * j: delta * (j+1)])\n",
    "    dump_data(metas, \"data/dump/metadata_{}-{}.pkl\".format(delta * j, delta * (j+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
